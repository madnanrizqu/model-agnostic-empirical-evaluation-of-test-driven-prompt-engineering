{
  "total_comparisons": 3,
  "td_better": 3,
  "td_same": 0,
  "td_worse": 0,
  "using_remediation": false,
  "details": {
    "code_contests_chatgpt4o": {
      "status": "better",
      "base_accuracy": 3.96,
      "td_accuracy": 26.24,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o_td/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o_td"
    },
    "code_contests_claude35sonnet": {
      "status": "better",
      "base_accuracy": 4.95,
      "td_accuracy": 37.62,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet_td/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet_td"
    },
    "code_contests_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 2.97,
      "td_accuracy": 31.19,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b_td"
    }
  },
  "rq_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2",
  "results_folder": "dynamic",
  "timestamp": "2025-10-16 21:24:28",
  "incomplete_directories": {
    "missing_td_dirs": [
      "manual_analysis"
    ],
    "missing_summary_files": [],
    "missing_accuracy_data": [],
    "partial_completion_dirs": [],
    "successful_comparisons": [
      "code_contests_chatgpt4o",
      "code_contests_claude35sonnet",
      "code_contests_qwen25coder32b"
    ],
    "config_mismatch_dirs": [],
    "total_directories": 4
  },
  "accuracy_statistics": {
    "increases": [
      22.279999999999998,
      32.669999999999995,
      28.220000000000002
    ],
    "total_increase": 83.16999999999999,
    "avg_increase": 27.723333333333333,
    "median_increase": 28.220000000000002,
    "std_dev": 5.2127759719110625,
    "min_increase": 22.279999999999998,
    "max_increase": 32.669999999999995,
    "percentile_25": 25.25,
    "percentile_75": 30.445,
    "interquartile_range": 5.195,
    "improved_count": 3,
    "worsened_count": 0,
    "same_count": 0,
    "avg_improvement_pct": 724.2648709315375,
    "avg_regression_pct": 0,
    "confidence_interval": [
      14.774079958763554,
      40.67258670790311
    ],
    "sorted_increases_desc": [
      {
        "benchmark": "code_contests_claude35sonnet",
        "base_accuracy": 4.95,
        "td_accuracy": 37.62,
        "increase": 32.669999999999995,
        "pct_change": 659.9999999999999
      },
      {
        "benchmark": "code_contests_qwen25coder32b",
        "base_accuracy": 2.97,
        "td_accuracy": 31.19,
        "increase": 28.220000000000002,
        "pct_change": 950.1683501683501
      },
      {
        "benchmark": "code_contests_chatgpt4o",
        "base_accuracy": 3.96,
        "td_accuracy": 26.24,
        "increase": 22.279999999999998,
        "pct_change": 562.6262626262626
      }
    ],
    "sorted_regressions_asc": [
      {
        "benchmark": "code_contests_chatgpt4o",
        "base_accuracy": 3.96,
        "td_accuracy": 26.24,
        "increase": 22.279999999999998,
        "pct_change": 562.6262626262626
      },
      {
        "benchmark": "code_contests_qwen25coder32b",
        "base_accuracy": 2.97,
        "td_accuracy": 31.19,
        "increase": 28.220000000000002,
        "pct_change": 950.1683501683501
      },
      {
        "benchmark": "code_contests_claude35sonnet",
        "base_accuracy": 4.95,
        "td_accuracy": 37.62,
        "increase": 32.669999999999995,
        "pct_change": 659.9999999999999
      }
    ],
    "normality_test_stat": 0.9931914729186166,
    "normality_p_value": 0.8422308757406574,
    "is_normal": true,
    "significance_test_type": "paired_t_test",
    "significance_test_stat": 9.211641196024226,
    "significance_p_value": 0.011580585269320686,
    "cohens_d": 6.769975801715259,
    "effect_size_interpretation": "large"
  }
}