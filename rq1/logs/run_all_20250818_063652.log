Log file created at: /Users/madnanrizqu/Code/thesis/rq2/logs/run_all_20250818_063652.log

--- CONFIGURATION SETTINGS ---
LLM_TO_USE: OPEN_LLM
RATIO_OF_ROWS_TO_RUN: 0.5
REATTEMPT_MAX_NUM: 5
RESULT_DIR_NAME: results_OPEN_LLM_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT
TEST_DRIVEN_RATIO: 0.5
----------------------------

Starting rq2/run_all.py in GENERATE-AND-TEST mode
Found 8 subdirectories to process: ['human_eval_chatgpt4o', 'human_eval_chatgpt4o_td', 'human_eval_chatgpt4omini', 'human_eval_chatgpt4omini_td', 'human_eval_claude35haiku', 'human_eval_claude35haiku_td', 'human_eval_claude35sonnet', 'human_eval_claude35sonnet_td']
Using 8 parallel workers
Starting parallel processing of 8 subdirectories
Processing: human_eval_chatgpt4o
Running get_solution.py for human_eval_chatgpt4o
Processing: human_eval_chatgpt4o_td
Running get_solution.py for human_eval_chatgpt4o_td
Starting: get_solution.py
Processing: human_eval_chatgpt4omini_td
Processing: human_eval_claude35haiku
Running get_solution.py for human_eval_claude35haiku
Starting: get_solution.py
Processing: human_eval_claude35haiku_td
Running get_solution.py for human_eval_claude35haiku_td
Processing: human_eval_claude35sonnet_td
Running get_solution.py for human_eval_chatgpt4omini_td
Processing: human_eval_chatgpt4omini
Running get_solution.py for human_eval_chatgpt4omini
Starting: get_solution.py
Processing: human_eval_claude35sonnet
Running get_solution.py for human_eval_claude35sonnet
Starting: get_solution.py
Starting: get_solution.py
Starting: get_solution.py
Starting: get_solution.py
Running get_solution.py for human_eval_claude35sonnet_td
Starting: get_solution.py
Completed: get_solution.py (119.2s)
Running test_solution.py for human_eval_chatgpt4o
Starting: test_solution.py
Completed: get_solution.py (125.5s)
Running test_solution.py for human_eval_chatgpt4o_td
Starting: test_solution.py
Completed: get_solution.py (161.5s)
Running test_solution.py for human_eval_chatgpt4omini
Starting: test_solution.py
Completed: get_solution.py (164.5s)
Running test_solution.py for human_eval_chatgpt4omini_td
Starting: test_solution.py
Completed: test_solution.py (58.1s)
Completed human_eval_chatgpt4o_td. Progress: 1/8 subdirectories completed (12.5%)
Completed: test_solution.py (98.3s)
Completed human_eval_chatgpt4o. Progress: 2/8 subdirectories completed (25.0%)
Completed: test_solution.py (96.1s)
Completed human_eval_chatgpt4omini_td. Progress: 3/8 subdirectories completed (37.5%)
Completed: get_solution.py (273.0s)
Running test_solution.py for human_eval_claude35sonnet
Starting: test_solution.py
Completed: get_solution.py (286.0s)
Running test_solution.py for human_eval_claude35sonnet_td
Starting: test_solution.py
Completed: test_solution.py (126.0s)
Completed human_eval_chatgpt4omini. Progress: 4/8 subdirectories completed (50.0%)
Completed: get_solution.py (345.7s)
Running test_solution.py for human_eval_claude35haiku
Starting: test_solution.py
Completed: get_solution.py (405.1s)
Running test_solution.py for human_eval_claude35haiku_td
Starting: test_solution.py
Completed: test_solution.py (125.1s)
Completed human_eval_claude35sonnet_td. Progress: 5/8 subdirectories completed (62.5%)
Completed: test_solution.py (157.8s)
Completed human_eval_claude35sonnet. Progress: 6/8 subdirectories completed (75.0%)
Completed: test_solution.py (134.8s)
Completed human_eval_claude35haiku_td. Progress: 7/8 subdirectories completed (87.5%)
Completed: test_solution.py (273.8s)
Completed human_eval_claude35haiku. Progress: 8/8 subdirectories completed (100.0%)
Completed all 8 subdirectories

--- PERFORMANCE BENCHMARK ---
Total execution time: 619.57 seconds

Subdirectory processing times:
  human_eval_chatgpt4o_td: 183.67 seconds
  human_eval_chatgpt4o: 217.48 seconds
  human_eval_chatgpt4omini_td: 260.64 seconds
  human_eval_chatgpt4omini: 287.42 seconds
  human_eval_claude35sonnet_td: 411.17 seconds
  human_eval_claude35sonnet: 430.87 seconds
  human_eval_claude35haiku_td: 539.85 seconds
  human_eval_claude35haiku: 619.56 seconds

get_solution.py execution times:
  human_eval_chatgpt4o: 119.22 seconds
  human_eval_chatgpt4o_td: 125.53 seconds
  human_eval_chatgpt4omini: 161.45 seconds
  human_eval_chatgpt4omini_td: 164.54 seconds
  human_eval_claude35sonnet: 273.03 seconds
  human_eval_claude35sonnet_td: 286.02 seconds
  human_eval_claude35haiku: 345.73 seconds
  human_eval_claude35haiku_td: 405.10 seconds

test_solution.py execution times:
  human_eval_chatgpt4o_td: 58.13 seconds
  human_eval_chatgpt4o: 98.26 seconds
  human_eval_chatgpt4omini_td: 96.10 seconds
  human_eval_chatgpt4omini: 125.96 seconds
  human_eval_claude35sonnet_td: 125.15 seconds
  human_eval_claude35sonnet: 157.84 seconds
  human_eval_claude35haiku_td: 134.75 seconds
  human_eval_claude35haiku: 273.82 seconds

--- CONFIGURATION SETTINGS ---
LLM_TO_USE: OPEN_LLM
RATIO_OF_ROWS_TO_RUN: 0.5
REATTEMPT_MAX_NUM: 5
RESULT_DIR_NAME: results_OPEN_LLM_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT
TEST_DRIVEN_RATIO: 0.5
----------------------------

Forcing garbage collection to free memory...
Garbage collection completed.

All processes completed. Log saved to: /Users/madnanrizqu/Code/thesis/rq2/logs/run_all_20250818_063652.log
