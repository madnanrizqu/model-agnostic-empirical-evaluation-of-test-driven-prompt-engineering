{
  "total_comparisons": 15,
  "td_better": 12,
  "td_same": 1,
  "td_worse": 2,
  "using_remediation": false,
  "details": {
    "code_contests_chatgpt4o": {
      "status": "better",
      "base_accuracy": 4.95,
      "td_accuracy": 27.72,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o_td/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o_td"
    },
    "code_contests_claude35sonnet": {
      "status": "better",
      "base_accuracy": 0.99,
      "td_accuracy": 36.63,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet_td/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet_td"
    },
    "code_contests_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 2.97,
      "td_accuracy": 18.81,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b_td"
    },
    "human_eval_chatgpt4o": {
      "status": "better",
      "base_accuracy": 78.05,
      "td_accuracy": 92.68,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4o/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4o_td/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4o_td"
    },
    "human_eval_chatgpt4omini": {
      "status": "same",
      "base_accuracy": 90.24,
      "td_accuracy": 90.24,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4omini/results_CHATGPT_4O_MINI_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4omini_td/results_CHATGPT_4O_MINI_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4omini",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4omini_td"
    },
    "human_eval_claude35haiku": {
      "status": "worse",
      "base_accuracy": 87.8,
      "td_accuracy": 85.37,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35haiku/results_CLAUDE_35_HAIKU_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35haiku_td/results_CLAUDE_35_HAIKU_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35haiku",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35haiku_td"
    },
    "human_eval_claude35sonnet": {
      "status": "worse",
      "base_accuracy": 92.68,
      "td_accuracy": 90.24,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35sonnet/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35sonnet_td/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35sonnet_td"
    },
    "human_eval_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 82.93,
      "td_accuracy": 85.37,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder32b_td"
    },
    "human_eval_qwen25coder7b": {
      "status": "better",
      "base_accuracy": 85.37,
      "td_accuracy": 87.8,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder7b/results_QWEN_7B_CODER_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder7b_td/results_QWEN_7B_CODER_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder7b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder7b_td"
    },
    "mbpp_sanitized_chatgpt4o": {
      "status": "better",
      "base_accuracy": 47.17,
      "td_accuracy": 89.62,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4o/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4o_td/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4o_td"
    },
    "mbpp_sanitized_chatgpt4omini": {
      "status": "better",
      "base_accuracy": 38.68,
      "td_accuracy": 84.91,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4omini/results_CHATGPT_4O_MINI_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4omini_td/results_CHATGPT_4O_MINI_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4omini",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4omini_td"
    },
    "mbpp_sanitized_claude35haiku": {
      "status": "better",
      "base_accuracy": 67.92,
      "td_accuracy": 82.08,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35haiku/results_CLAUDE_35_HAIKU_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35haiku_td/results_CLAUDE_35_HAIKU_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35haiku",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35haiku_td"
    },
    "mbpp_sanitized_claude35sonnet": {
      "status": "better",
      "base_accuracy": 59.43,
      "td_accuracy": 87.74,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35sonnet/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35sonnet_td/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35sonnet_td"
    },
    "mbpp_sanitized_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 23.58,
      "td_accuracy": 58.49,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder32b_td"
    },
    "mbpp_sanitized_qwen25coder7b": {
      "status": "better",
      "base_accuracy": 59.43,
      "td_accuracy": 81.13,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder7b/results_QWEN_7B_CODER_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder7b_td/results_QWEN_7B_CODER_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder7b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder7b_td"
    }
  },
  "rq_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2",
  "results_folder": "dynamic",
  "timestamp": "2025-08-16 11:35:00",
  "incomplete_directories": {
    "missing_td_dirs": [],
    "missing_summary_files": [],
    "missing_accuracy_data": [],
    "partial_completion_dirs": [],
    "successful_comparisons": [
      "code_contests_chatgpt4o",
      "code_contests_claude35sonnet",
      "code_contests_qwen25coder32b",
      "human_eval_chatgpt4o",
      "human_eval_chatgpt4omini",
      "human_eval_claude35haiku",
      "human_eval_claude35sonnet",
      "human_eval_qwen25coder32b",
      "human_eval_qwen25coder7b",
      "mbpp_sanitized_chatgpt4o",
      "mbpp_sanitized_chatgpt4omini",
      "mbpp_sanitized_claude35haiku",
      "mbpp_sanitized_claude35sonnet",
      "mbpp_sanitized_qwen25coder32b",
      "mbpp_sanitized_qwen25coder7b"
    ],
    "config_mismatch_dirs": [],
    "total_directories": 15
  },
  "accuracy_statistics": {
    "increases": [
      22.77,
      35.64,
      15.839999999999998,
      14.63000000000001,
      0.0,
      -2.4299999999999926,
      -2.440000000000012,
      2.4399999999999977,
      2.4299999999999926,
      42.45,
      46.23,
      14.159999999999997,
      28.309999999999995,
      34.910000000000004,
      21.699999999999996
    ],
    "total_increase": 276.64,
    "avg_increase": 18.442666666666664,
    "median_increase": 15.839999999999998,
    "std_dev": 16.488389623639794,
    "min_increase": -2.440000000000012,
    "max_increase": 46.23,
    "percentile_25": 2.434999999999995,
    "percentile_75": 31.61,
    "interquartile_range": 29.175000000000004,
    "improved_count": 12,
    "worsened_count": 2,
    "same_count": 1,
    "avg_improvement_pct": 423.36882026526956,
    "avg_regression_pct": -2.7001842379245042,
    "confidence_interval": [
      9.311700842968978,
      27.57363249036435
    ],
    "sorted_increases_desc": [
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini",
        "base_accuracy": 38.68,
        "td_accuracy": 84.91,
        "increase": 46.23,
        "pct_change": 119.51913133402275
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4o",
        "base_accuracy": 47.17,
        "td_accuracy": 89.62,
        "increase": 42.45,
        "pct_change": 89.9936400254399
      },
      {
        "benchmark": "code_contests_claude35sonnet",
        "base_accuracy": 0.99,
        "td_accuracy": 36.63,
        "increase": 35.64,
        "pct_change": 3600.0
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b",
        "base_accuracy": 23.58,
        "td_accuracy": 58.49,
        "increase": 34.910000000000004,
        "pct_change": 148.04919423240037
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet",
        "base_accuracy": 59.43,
        "td_accuracy": 87.74,
        "increase": 28.309999999999995,
        "pct_change": 47.63587413764092
      },
      {
        "benchmark": "code_contests_chatgpt4o",
        "base_accuracy": 4.95,
        "td_accuracy": 27.72,
        "increase": 22.77,
        "pct_change": 459.99999999999994
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b",
        "base_accuracy": 59.43,
        "td_accuracy": 81.13,
        "increase": 21.699999999999996,
        "pct_change": 36.5135453474676
      },
      {
        "benchmark": "code_contests_qwen25coder32b",
        "base_accuracy": 2.97,
        "td_accuracy": 18.81,
        "increase": 15.839999999999998,
        "pct_change": 533.3333333333333
      },
      {
        "benchmark": "human_eval_chatgpt4o",
        "base_accuracy": 78.05,
        "td_accuracy": 92.68,
        "increase": 14.63000000000001,
        "pct_change": 18.744394618834093
      },
      {
        "benchmark": "mbpp_sanitized_claude35haiku",
        "base_accuracy": 67.92,
        "td_accuracy": 82.08,
        "increase": 14.159999999999997,
        "pct_change": 20.84805653710247
      },
      {
        "benchmark": "human_eval_qwen25coder32b",
        "base_accuracy": 82.93,
        "td_accuracy": 85.37,
        "increase": 2.4399999999999977,
        "pct_change": 2.942240443747736
      },
      {
        "benchmark": "human_eval_qwen25coder7b",
        "base_accuracy": 85.37,
        "td_accuracy": 87.8,
        "increase": 2.4299999999999926,
        "pct_change": 2.846433173245862
      },
      {
        "benchmark": "human_eval_chatgpt4omini",
        "base_accuracy": 90.24,
        "td_accuracy": 90.24,
        "increase": 0.0,
        "pct_change": 0.0
      },
      {
        "benchmark": "human_eval_claude35haiku",
        "base_accuracy": 87.8,
        "td_accuracy": 85.37,
        "increase": -2.4299999999999926,
        "pct_change": -2.7676537585421332
      },
      {
        "benchmark": "human_eval_claude35sonnet",
        "base_accuracy": 92.68,
        "td_accuracy": 90.24,
        "increase": -2.440000000000012,
        "pct_change": -2.632714717306875
      }
    ],
    "sorted_regressions_asc": [
      {
        "benchmark": "human_eval_claude35sonnet",
        "base_accuracy": 92.68,
        "td_accuracy": 90.24,
        "increase": -2.440000000000012,
        "pct_change": -2.632714717306875
      },
      {
        "benchmark": "human_eval_claude35haiku",
        "base_accuracy": 87.8,
        "td_accuracy": 85.37,
        "increase": -2.4299999999999926,
        "pct_change": -2.7676537585421332
      },
      {
        "benchmark": "human_eval_chatgpt4omini",
        "base_accuracy": 90.24,
        "td_accuracy": 90.24,
        "increase": 0.0,
        "pct_change": 0.0
      },
      {
        "benchmark": "human_eval_qwen25coder7b",
        "base_accuracy": 85.37,
        "td_accuracy": 87.8,
        "increase": 2.4299999999999926,
        "pct_change": 2.846433173245862
      },
      {
        "benchmark": "human_eval_qwen25coder32b",
        "base_accuracy": 82.93,
        "td_accuracy": 85.37,
        "increase": 2.4399999999999977,
        "pct_change": 2.942240443747736
      },
      {
        "benchmark": "mbpp_sanitized_claude35haiku",
        "base_accuracy": 67.92,
        "td_accuracy": 82.08,
        "increase": 14.159999999999997,
        "pct_change": 20.84805653710247
      },
      {
        "benchmark": "human_eval_chatgpt4o",
        "base_accuracy": 78.05,
        "td_accuracy": 92.68,
        "increase": 14.63000000000001,
        "pct_change": 18.744394618834093
      },
      {
        "benchmark": "code_contests_qwen25coder32b",
        "base_accuracy": 2.97,
        "td_accuracy": 18.81,
        "increase": 15.839999999999998,
        "pct_change": 533.3333333333333
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b",
        "base_accuracy": 59.43,
        "td_accuracy": 81.13,
        "increase": 21.699999999999996,
        "pct_change": 36.5135453474676
      },
      {
        "benchmark": "code_contests_chatgpt4o",
        "base_accuracy": 4.95,
        "td_accuracy": 27.72,
        "increase": 22.77,
        "pct_change": 459.99999999999994
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet",
        "base_accuracy": 59.43,
        "td_accuracy": 87.74,
        "increase": 28.309999999999995,
        "pct_change": 47.63587413764092
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b",
        "base_accuracy": 23.58,
        "td_accuracy": 58.49,
        "increase": 34.910000000000004,
        "pct_change": 148.04919423240037
      },
      {
        "benchmark": "code_contests_claude35sonnet",
        "base_accuracy": 0.99,
        "td_accuracy": 36.63,
        "increase": 35.64,
        "pct_change": 3600.0
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4o",
        "base_accuracy": 47.17,
        "td_accuracy": 89.62,
        "increase": 42.45,
        "pct_change": 89.9936400254399
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini",
        "base_accuracy": 38.68,
        "td_accuracy": 84.91,
        "increase": 46.23,
        "pct_change": 119.51913133402275
      }
    ],
    "normality_test_stat": 0.9289653054013658,
    "normality_p_value": 0.2633159053621532,
    "is_normal": true,
    "significance_test_type": "paired_t_test",
    "significance_test_stat": 4.332026504107255,
    "significance_p_value": 0.0006895075215226215,
    "cohens_d": 0.6243583793263782,
    "effect_size_interpretation": "medium"
  }
}