{
  "total_comparisons": 15,
  "td_better": 12,
  "td_same": 3,
  "td_worse": 0,
  "using_remediation": true,
  "details": {
    "code_contests_chatgpt4o": {
      "status": "better",
      "base_accuracy": 22.77,
      "td_accuracy": 31.68,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o_td/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_chatgpt4o_td"
    },
    "code_contests_claude35sonnet": {
      "status": "better",
      "base_accuracy": 47.52,
      "td_accuracy": 53.47,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet_td/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_claude35sonnet_td"
    },
    "code_contests_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 6.93,
      "td_accuracy": 22.77,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/code_contests_qwen25coder32b_td"
    },
    "human_eval_chatgpt4o": {
      "status": "same",
      "base_accuracy": 92.68,
      "td_accuracy": 92.68,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4o/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4o_td/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4o_td"
    },
    "human_eval_chatgpt4omini": {
      "status": "better",
      "base_accuracy": 95.12,
      "td_accuracy": 97.56,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4omini/results_CHATGPT_4O_MINI_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4omini_td/results_CHATGPT_4O_MINI_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4omini",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_chatgpt4omini_td"
    },
    "human_eval_claude35haiku": {
      "status": "same",
      "base_accuracy": 95.12,
      "td_accuracy": 95.12,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35haiku/results_CLAUDE_35_HAIKU_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35haiku_td/results_CLAUDE_35_HAIKU_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35haiku",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35haiku_td"
    },
    "human_eval_claude35sonnet": {
      "status": "same",
      "base_accuracy": 95.12,
      "td_accuracy": 95.12,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35sonnet/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35sonnet_td/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_claude35sonnet_td"
    },
    "human_eval_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 87.8,
      "td_accuracy": 90.24,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder32b_td"
    },
    "human_eval_qwen25coder7b": {
      "status": "better",
      "base_accuracy": 85.37,
      "td_accuracy": 87.8,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder7b/results_QWEN_7B_CODER_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder7b_td/results_QWEN_7B_CODER_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder7b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/human_eval_qwen25coder7b_td"
    },
    "mbpp_sanitized_chatgpt4o": {
      "status": "better",
      "base_accuracy": 83.96,
      "td_accuracy": 93.4,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4o/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4o_td/results_CHATGPT_4O_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4o_td"
    },
    "mbpp_sanitized_chatgpt4omini": {
      "status": "better",
      "base_accuracy": 57.55,
      "td_accuracy": 86.79,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4omini/results_CHATGPT_4O_MINI_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4omini_td/results_CHATGPT_4O_MINI_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4omini",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_chatgpt4omini_td"
    },
    "mbpp_sanitized_claude35haiku": {
      "status": "better",
      "base_accuracy": 91.51,
      "td_accuracy": 92.45,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35haiku/results_CLAUDE_35_HAIKU_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35haiku_td/results_CLAUDE_35_HAIKU_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35haiku",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35haiku_td"
    },
    "mbpp_sanitized_claude35sonnet": {
      "status": "better",
      "base_accuracy": 91.51,
      "td_accuracy": 95.28,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35sonnet/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35sonnet_td/results_CLAUDE_35_SONNET_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_claude35sonnet_td"
    },
    "mbpp_sanitized_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 43.4,
      "td_accuracy": 73.58,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder32b_td"
    },
    "mbpp_sanitized_qwen25coder7b": {
      "status": "better",
      "base_accuracy": 59.43,
      "td_accuracy": 82.08,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder7b/results_QWEN_7B_CODER_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder7b_td/results_QWEN_7B_CODER_0.25_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder7b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2/mbpp_sanitized_qwen25coder7b_td"
    }
  },
  "rq_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq2",
  "results_folder": "dynamic",
  "timestamp": "2025-08-16 11:35:00",
  "incomplete_directories": {
    "missing_td_dirs": [],
    "missing_summary_files": [],
    "missing_accuracy_data": [],
    "partial_completion_dirs": [],
    "successful_comparisons": [
      "code_contests_chatgpt4o",
      "code_contests_claude35sonnet",
      "code_contests_qwen25coder32b",
      "human_eval_chatgpt4o",
      "human_eval_chatgpt4omini",
      "human_eval_claude35haiku",
      "human_eval_claude35sonnet",
      "human_eval_qwen25coder32b",
      "human_eval_qwen25coder7b",
      "mbpp_sanitized_chatgpt4o",
      "mbpp_sanitized_chatgpt4omini",
      "mbpp_sanitized_claude35haiku",
      "mbpp_sanitized_claude35sonnet",
      "mbpp_sanitized_qwen25coder32b",
      "mbpp_sanitized_qwen25coder7b"
    ],
    "config_mismatch_dirs": [],
    "total_directories": 15
  },
  "accuracy_statistics": {
    "increases": [
      8.91,
      5.949999999999996,
      15.84,
      0.0,
      2.4399999999999977,
      0.0,
      0.0,
      2.4399999999999977,
      2.4299999999999926,
      9.440000000000012,
      29.24000000000001,
      0.9399999999999977,
      3.769999999999996,
      30.18,
      22.65
    ],
    "total_increase": 134.23,
    "avg_increase": 8.948666666666666,
    "median_increase": 3.769999999999996,
    "std_dev": 10.574130742164153,
    "min_increase": 0.0,
    "max_increase": 30.18,
    "percentile_25": 1.6849999999999952,
    "percentile_75": 12.640000000000006,
    "interquartile_range": 10.95500000000001,
    "improved_count": 12,
    "worsened_count": 0,
    "same_count": 3,
    "avg_improvement_pct": 38.605268358904034,
    "avg_regression_pct": 0,
    "confidence_interval": [
      3.092908243564935,
      14.804425089768397
    ],
    "sorted_increases_desc": [
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b",
        "base_accuracy": 43.4,
        "td_accuracy": 73.58,
        "increase": 30.18,
        "pct_change": 69.53917050691244
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini",
        "base_accuracy": 57.55,
        "td_accuracy": 86.79,
        "increase": 29.24000000000001,
        "pct_change": 50.80799304952217
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b",
        "base_accuracy": 59.43,
        "td_accuracy": 82.08,
        "increase": 22.65,
        "pct_change": 38.1120646138314
      },
      {
        "benchmark": "code_contests_qwen25coder32b",
        "base_accuracy": 6.93,
        "td_accuracy": 22.77,
        "increase": 15.84,
        "pct_change": 228.57142857142856
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4o",
        "base_accuracy": 83.96,
        "td_accuracy": 93.4,
        "increase": 9.440000000000012,
        "pct_change": 11.243449261553137
      },
      {
        "benchmark": "code_contests_chatgpt4o",
        "base_accuracy": 22.77,
        "td_accuracy": 31.68,
        "increase": 8.91,
        "pct_change": 39.130434782608695
      },
      {
        "benchmark": "code_contests_claude35sonnet",
        "base_accuracy": 47.52,
        "td_accuracy": 53.47,
        "increase": 5.949999999999996,
        "pct_change": 12.521043771043761
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet",
        "base_accuracy": 91.51,
        "td_accuracy": 95.28,
        "increase": 3.769999999999996,
        "pct_change": 4.1197683313299045
      },
      {
        "benchmark": "human_eval_chatgpt4omini",
        "base_accuracy": 95.12,
        "td_accuracy": 97.56,
        "increase": 2.4399999999999977,
        "pct_change": 2.565180824222033
      },
      {
        "benchmark": "human_eval_qwen25coder32b",
        "base_accuracy": 87.8,
        "td_accuracy": 90.24,
        "increase": 2.4399999999999977,
        "pct_change": 2.77904328018223
      },
      {
        "benchmark": "human_eval_qwen25coder7b",
        "base_accuracy": 85.37,
        "td_accuracy": 87.8,
        "increase": 2.4299999999999926,
        "pct_change": 2.846433173245862
      },
      {
        "benchmark": "mbpp_sanitized_claude35haiku",
        "base_accuracy": 91.51,
        "td_accuracy": 92.45,
        "increase": 0.9399999999999977,
        "pct_change": 1.0272101409681977
      },
      {
        "benchmark": "human_eval_chatgpt4o",
        "base_accuracy": 92.68,
        "td_accuracy": 92.68,
        "increase": 0.0,
        "pct_change": 0.0
      },
      {
        "benchmark": "human_eval_claude35haiku",
        "base_accuracy": 95.12,
        "td_accuracy": 95.12,
        "increase": 0.0,
        "pct_change": 0.0
      },
      {
        "benchmark": "human_eval_claude35sonnet",
        "base_accuracy": 95.12,
        "td_accuracy": 95.12,
        "increase": 0.0,
        "pct_change": 0.0
      }
    ],
    "sorted_regressions_asc": [
      {
        "benchmark": "human_eval_chatgpt4o",
        "base_accuracy": 92.68,
        "td_accuracy": 92.68,
        "increase": 0.0,
        "pct_change": 0.0
      },
      {
        "benchmark": "human_eval_claude35haiku",
        "base_accuracy": 95.12,
        "td_accuracy": 95.12,
        "increase": 0.0,
        "pct_change": 0.0
      },
      {
        "benchmark": "human_eval_claude35sonnet",
        "base_accuracy": 95.12,
        "td_accuracy": 95.12,
        "increase": 0.0,
        "pct_change": 0.0
      },
      {
        "benchmark": "mbpp_sanitized_claude35haiku",
        "base_accuracy": 91.51,
        "td_accuracy": 92.45,
        "increase": 0.9399999999999977,
        "pct_change": 1.0272101409681977
      },
      {
        "benchmark": "human_eval_qwen25coder7b",
        "base_accuracy": 85.37,
        "td_accuracy": 87.8,
        "increase": 2.4299999999999926,
        "pct_change": 2.846433173245862
      },
      {
        "benchmark": "human_eval_chatgpt4omini",
        "base_accuracy": 95.12,
        "td_accuracy": 97.56,
        "increase": 2.4399999999999977,
        "pct_change": 2.565180824222033
      },
      {
        "benchmark": "human_eval_qwen25coder32b",
        "base_accuracy": 87.8,
        "td_accuracy": 90.24,
        "increase": 2.4399999999999977,
        "pct_change": 2.77904328018223
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet",
        "base_accuracy": 91.51,
        "td_accuracy": 95.28,
        "increase": 3.769999999999996,
        "pct_change": 4.1197683313299045
      },
      {
        "benchmark": "code_contests_claude35sonnet",
        "base_accuracy": 47.52,
        "td_accuracy": 53.47,
        "increase": 5.949999999999996,
        "pct_change": 12.521043771043761
      },
      {
        "benchmark": "code_contests_chatgpt4o",
        "base_accuracy": 22.77,
        "td_accuracy": 31.68,
        "increase": 8.91,
        "pct_change": 39.130434782608695
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4o",
        "base_accuracy": 83.96,
        "td_accuracy": 93.4,
        "increase": 9.440000000000012,
        "pct_change": 11.243449261553137
      },
      {
        "benchmark": "code_contests_qwen25coder32b",
        "base_accuracy": 6.93,
        "td_accuracy": 22.77,
        "increase": 15.84,
        "pct_change": 228.57142857142856
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b",
        "base_accuracy": 59.43,
        "td_accuracy": 82.08,
        "increase": 22.65,
        "pct_change": 38.1120646138314
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini",
        "base_accuracy": 57.55,
        "td_accuracy": 86.79,
        "increase": 29.24000000000001,
        "pct_change": 50.80799304952217
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b",
        "base_accuracy": 43.4,
        "td_accuracy": 73.58,
        "increase": 30.18,
        "pct_change": 69.53917050691244
      }
    ],
    "normality_test_stat": 0.7973304742955888,
    "normality_p_value": 0.0033981525739292502,
    "is_normal": false,
    "significance_test_type": "wilcoxon_signed_rank",
    "significance_test_stat": 0.0,
    "significance_p_value": 0.0022090203462313877,
    "cohens_d": 0.33629714209300626,
    "effect_size_interpretation": "small"
  }
}