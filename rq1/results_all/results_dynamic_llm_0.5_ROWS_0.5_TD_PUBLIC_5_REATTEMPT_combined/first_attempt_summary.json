{
  "total_comparisons": 16,
  "td_better": 16,
  "td_same": 0,
  "td_worse": 0,
  "using_remediation": false,
  "details": {
    "human_eval_chatgpt4o_combined": {
      "status": "better",
      "base_accuracy": 81.71,
      "td_accuracy": 83.54,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o_combined_td"
    },
    "human_eval_chatgpt4omini_combined": {
      "status": "better",
      "base_accuracy": 79.88,
      "td_accuracy": 81.71,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini_combined_td"
    },
    "human_eval_claude35haiku_combined": {
      "status": "better",
      "base_accuracy": 82.32,
      "td_accuracy": 85.37,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku_combined_td"
    },
    "human_eval_claude35sonnet_combined": {
      "status": "better",
      "base_accuracy": 87.2,
      "td_accuracy": 88.41,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet_combined_td"
    },
    "human_eval_qwen25coder14b_combined": {
      "status": "better",
      "base_accuracy": 80.49,
      "td_accuracy": 85.98,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b_combined_td"
    },
    "human_eval_qwen25coder32b_combined": {
      "status": "better",
      "base_accuracy": 81.71,
      "td_accuracy": 87.2,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b_combined_td"
    },
    "human_eval_qwen25coder3b_combined": {
      "status": "better",
      "base_accuracy": 76.22,
      "td_accuracy": 78.66,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b_combined_td"
    },
    "human_eval_qwen25coder7b_combined": {
      "status": "better",
      "base_accuracy": 79.27,
      "td_accuracy": 80.49,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b_combined_td"
    },
    "mbpp_sanitized_chatgpt4o_combined": {
      "status": "better",
      "base_accuracy": 73.07,
      "td_accuracy": 84.31,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o_combined_td"
    },
    "mbpp_sanitized_chatgpt4omini_combined": {
      "status": "better",
      "base_accuracy": 70.73,
      "td_accuracy": 79.63,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini_combined_td"
    },
    "mbpp_sanitized_claude35haiku_combined": {
      "status": "better",
      "base_accuracy": 73.77,
      "td_accuracy": 83.84,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku_combined_td"
    },
    "mbpp_sanitized_claude35sonnet_combined": {
      "status": "better",
      "base_accuracy": 75.64,
      "td_accuracy": 85.95,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet_combined_td"
    },
    "mbpp_sanitized_qwen25coder14b_combined": {
      "status": "better",
      "base_accuracy": 72.37,
      "td_accuracy": 81.73,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder14b_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder14b_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder14b_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder14b_combined_td"
    },
    "mbpp_sanitized_qwen25coder32b_combined": {
      "status": "better",
      "base_accuracy": 73.54,
      "td_accuracy": 82.2,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b_combined_td"
    },
    "mbpp_sanitized_qwen25coder3b_combined": {
      "status": "better",
      "base_accuracy": 63.7,
      "td_accuracy": 68.15,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b_combined_td"
    },
    "mbpp_sanitized_qwen25coder7b_combined": {
      "status": "better",
      "base_accuracy": 65.34,
      "td_accuracy": 77.28,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b_combined/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b_combined_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT_combined/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b_combined",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b_combined_td"
    }
  },
  "rq_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1",
  "results_folder": "dynamic",
  "timestamp": "2025-10-17 22:52:19",
  "incomplete_directories": {
    "missing_td_dirs": [],
    "missing_summary_files": [],
    "missing_accuracy_data": [],
    "partial_completion_dirs": [],
    "successful_comparisons": [
      "human_eval_chatgpt4o_combined",
      "human_eval_chatgpt4omini_combined",
      "human_eval_claude35haiku_combined",
      "human_eval_claude35sonnet_combined",
      "human_eval_qwen25coder14b_combined",
      "human_eval_qwen25coder32b_combined",
      "human_eval_qwen25coder3b_combined",
      "human_eval_qwen25coder7b_combined",
      "mbpp_sanitized_chatgpt4o_combined",
      "mbpp_sanitized_chatgpt4omini_combined",
      "mbpp_sanitized_claude35haiku_combined",
      "mbpp_sanitized_claude35sonnet_combined",
      "mbpp_sanitized_qwen25coder14b_combined",
      "mbpp_sanitized_qwen25coder32b_combined",
      "mbpp_sanitized_qwen25coder3b_combined",
      "mbpp_sanitized_qwen25coder7b_combined"
    ],
    "config_mismatch_dirs": [],
    "total_directories": 16
  },
  "accuracy_statistics": {
    "increases": [
      1.8300000000000125,
      1.8299999999999983,
      3.0500000000000114,
      1.2099999999999937,
      5.490000000000009,
      5.490000000000009,
      2.4399999999999977,
      1.2199999999999989,
      11.240000000000009,
      8.899999999999991,
      10.070000000000007,
      10.310000000000002,
      9.36,
      8.659999999999997,
      4.450000000000003,
      11.939999999999998
    ],
    "total_increase": 97.49000000000004,
    "avg_increase": 6.093125000000002,
    "median_increase": 5.490000000000009,
    "std_dev": 3.9105646970738124,
    "min_increase": 1.2099999999999937,
    "max_increase": 11.939999999999998,
    "percentile_25": 2.2875000000000014,
    "percentile_75": 9.537500000000001,
    "interquartile_range": 7.25,
    "improved_count": 16,
    "worsened_count": 0,
    "same_count": 0,
    "avg_improvement_pct": 8.31991011338035,
    "avg_regression_pct": 0,
    "confidence_interval": [
      4.009332163385425,
      8.17691783661458
    ],
    "sorted_increases_desc": [
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b_combined",
        "base_accuracy": 65.34,
        "td_accuracy": 77.28,
        "increase": 11.939999999999998,
        "pct_change": 18.273645546372816
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4o_combined",
        "base_accuracy": 73.07,
        "td_accuracy": 84.31,
        "increase": 11.240000000000009,
        "pct_change": 15.382509921992623
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet_combined",
        "base_accuracy": 75.64,
        "td_accuracy": 85.95,
        "increase": 10.310000000000002,
        "pct_change": 13.63035430988895
      },
      {
        "benchmark": "mbpp_sanitized_claude35haiku_combined",
        "base_accuracy": 73.77,
        "td_accuracy": 83.84,
        "increase": 10.070000000000007,
        "pct_change": 13.650535448014109
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder14b_combined",
        "base_accuracy": 72.37,
        "td_accuracy": 81.73,
        "increase": 9.36,
        "pct_change": 12.933535995578277
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini_combined",
        "base_accuracy": 70.73,
        "td_accuracy": 79.63,
        "increase": 8.899999999999991,
        "pct_change": 12.583062349780844
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b_combined",
        "base_accuracy": 73.54,
        "td_accuracy": 82.2,
        "increase": 8.659999999999997,
        "pct_change": 11.775904269785146
      },
      {
        "benchmark": "human_eval_qwen25coder14b_combined",
        "base_accuracy": 80.49,
        "td_accuracy": 85.98,
        "increase": 5.490000000000009,
        "pct_change": 6.820723071188979
      },
      {
        "benchmark": "human_eval_qwen25coder32b_combined",
        "base_accuracy": 81.71,
        "td_accuracy": 87.2,
        "increase": 5.490000000000009,
        "pct_change": 6.718883857544988
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder3b_combined",
        "base_accuracy": 63.7,
        "td_accuracy": 68.15,
        "increase": 4.450000000000003,
        "pct_change": 6.9858712715855615
      },
      {
        "benchmark": "human_eval_claude35haiku_combined",
        "base_accuracy": 82.32,
        "td_accuracy": 85.37,
        "increase": 3.0500000000000114,
        "pct_change": 3.705053449951423
      },
      {
        "benchmark": "human_eval_qwen25coder3b_combined",
        "base_accuracy": 76.22,
        "td_accuracy": 78.66,
        "increase": 2.4399999999999977,
        "pct_change": 3.2012595119391203
      },
      {
        "benchmark": "human_eval_chatgpt4o_combined",
        "base_accuracy": 81.71,
        "td_accuracy": 83.54,
        "increase": 1.8300000000000125,
        "pct_change": 2.2396279525150073
      },
      {
        "benchmark": "human_eval_chatgpt4omini_combined",
        "base_accuracy": 79.88,
        "td_accuracy": 81.71,
        "increase": 1.8299999999999983,
        "pct_change": 2.2909364046069083
      },
      {
        "benchmark": "human_eval_qwen25coder7b_combined",
        "base_accuracy": 79.27,
        "td_accuracy": 80.49,
        "increase": 1.2199999999999989,
        "pct_change": 1.5390437744417798
      },
      {
        "benchmark": "human_eval_claude35sonnet_combined",
        "base_accuracy": 87.2,
        "td_accuracy": 88.41,
        "increase": 1.2099999999999937,
        "pct_change": 1.3876146788990753
      }
    ],
    "sorted_regressions_asc": [
      {
        "benchmark": "human_eval_claude35sonnet_combined",
        "base_accuracy": 87.2,
        "td_accuracy": 88.41,
        "increase": 1.2099999999999937,
        "pct_change": 1.3876146788990753
      },
      {
        "benchmark": "human_eval_qwen25coder7b_combined",
        "base_accuracy": 79.27,
        "td_accuracy": 80.49,
        "increase": 1.2199999999999989,
        "pct_change": 1.5390437744417798
      },
      {
        "benchmark": "human_eval_chatgpt4omini_combined",
        "base_accuracy": 79.88,
        "td_accuracy": 81.71,
        "increase": 1.8299999999999983,
        "pct_change": 2.2909364046069083
      },
      {
        "benchmark": "human_eval_chatgpt4o_combined",
        "base_accuracy": 81.71,
        "td_accuracy": 83.54,
        "increase": 1.8300000000000125,
        "pct_change": 2.2396279525150073
      },
      {
        "benchmark": "human_eval_qwen25coder3b_combined",
        "base_accuracy": 76.22,
        "td_accuracy": 78.66,
        "increase": 2.4399999999999977,
        "pct_change": 3.2012595119391203
      },
      {
        "benchmark": "human_eval_claude35haiku_combined",
        "base_accuracy": 82.32,
        "td_accuracy": 85.37,
        "increase": 3.0500000000000114,
        "pct_change": 3.705053449951423
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder3b_combined",
        "base_accuracy": 63.7,
        "td_accuracy": 68.15,
        "increase": 4.450000000000003,
        "pct_change": 6.9858712715855615
      },
      {
        "benchmark": "human_eval_qwen25coder14b_combined",
        "base_accuracy": 80.49,
        "td_accuracy": 85.98,
        "increase": 5.490000000000009,
        "pct_change": 6.820723071188979
      },
      {
        "benchmark": "human_eval_qwen25coder32b_combined",
        "base_accuracy": 81.71,
        "td_accuracy": 87.2,
        "increase": 5.490000000000009,
        "pct_change": 6.718883857544988
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b_combined",
        "base_accuracy": 73.54,
        "td_accuracy": 82.2,
        "increase": 8.659999999999997,
        "pct_change": 11.775904269785146
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini_combined",
        "base_accuracy": 70.73,
        "td_accuracy": 79.63,
        "increase": 8.899999999999991,
        "pct_change": 12.583062349780844
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder14b_combined",
        "base_accuracy": 72.37,
        "td_accuracy": 81.73,
        "increase": 9.36,
        "pct_change": 12.933535995578277
      },
      {
        "benchmark": "mbpp_sanitized_claude35haiku_combined",
        "base_accuracy": 73.77,
        "td_accuracy": 83.84,
        "increase": 10.070000000000007,
        "pct_change": 13.650535448014109
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet_combined",
        "base_accuracy": 75.64,
        "td_accuracy": 85.95,
        "increase": 10.310000000000002,
        "pct_change": 13.63035430988895
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4o_combined",
        "base_accuracy": 73.07,
        "td_accuracy": 84.31,
        "increase": 11.240000000000009,
        "pct_change": 15.382509921992623
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b_combined",
        "base_accuracy": 65.34,
        "td_accuracy": 77.28,
        "increase": 11.939999999999998,
        "pct_change": 18.273645546372816
      }
    ],
    "normality_test_stat": 0.8911194992493474,
    "normality_p_value": 0.058023430876500255,
    "is_normal": true,
    "significance_test_type": "paired_t_test",
    "significance_test_stat": 6.232475841209686,
    "significance_p_value": 1.604439714797643e-05,
    "cohens_d": 1.0787532449754935,
    "effect_size_interpretation": "large"
  }
}