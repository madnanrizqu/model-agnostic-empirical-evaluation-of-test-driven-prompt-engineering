{
  "total_comparisons": 15,
  "td_better": 15,
  "td_same": 0,
  "td_worse": 0,
  "using_remediation": true,
  "details": {
    "human_eval_chatgpt4o": {
      "status": "better",
      "base_accuracy": 90.24,
      "td_accuracy": 92.68,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o_td/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o_td"
    },
    "human_eval_chatgpt4omini": {
      "status": "better",
      "base_accuracy": 87.8,
      "td_accuracy": 90.24,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini_td"
    },
    "human_eval_claude35haiku": {
      "status": "better",
      "base_accuracy": 90.24,
      "td_accuracy": 95.12,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku/results_CLAUDE_35_HAIKU_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku_td/results_CLAUDE_35_HAIKU_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku_td"
    },
    "human_eval_claude35sonnet": {
      "status": "better",
      "base_accuracy": 91.46,
      "td_accuracy": 93.9,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet_td/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet_td"
    },
    "human_eval_qwen25coder14b": {
      "status": "better",
      "base_accuracy": 79.27,
      "td_accuracy": 90.24,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b/results_QWEN_14B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b_td/results_QWEN_14B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b_td"
    },
    "human_eval_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 89.02,
      "td_accuracy": 93.9,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b_td"
    },
    "human_eval_qwen25coder3b": {
      "status": "better",
      "base_accuracy": 75.61,
      "td_accuracy": 79.27,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b/results_QWEN_3B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b_td/results_QWEN_3B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b_td"
    },
    "human_eval_qwen25coder7b": {
      "status": "better",
      "base_accuracy": 76.83,
      "td_accuracy": 84.15,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b/results_QWEN_7B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b_td/results_QWEN_7B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b_td"
    },
    "mbpp_sanitized_chatgpt4o": {
      "status": "better",
      "base_accuracy": 89.67,
      "td_accuracy": 92.96,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o_td/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o_td"
    },
    "mbpp_sanitized_chatgpt4omini": {
      "status": "better",
      "base_accuracy": 85.45,
      "td_accuracy": 87.32,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini_td"
    },
    "mbpp_sanitized_claude35haiku": {
      "status": "better",
      "base_accuracy": 91.08,
      "td_accuracy": 92.02,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku/results_CLAUDE_35_HAIKU_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku_td/results_CLAUDE_35_HAIKU_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku_td"
    },
    "mbpp_sanitized_claude35sonnet": {
      "status": "better",
      "base_accuracy": 93.43,
      "td_accuracy": 95.31,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet_td/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet_td"
    },
    "mbpp_sanitized_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 84.98,
      "td_accuracy": 89.67,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b_td"
    },
    "mbpp_sanitized_qwen25coder3b": {
      "status": "better",
      "base_accuracy": 67.14,
      "td_accuracy": 71.36,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b/results_QWEN_3B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b_td/results_QWEN_3B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b_td"
    },
    "mbpp_sanitized_qwen25coder7b": {
      "status": "better",
      "base_accuracy": 72.77,
      "td_accuracy": 81.22,
      "using_remediation": true,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b/results_QWEN_7B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b_td/results_QWEN_7B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b_td"
    }
  },
  "rq_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1",
  "results_folder": "dynamic",
  "timestamp": "2025-10-16 21:16:11",
  "incomplete_directories": {
    "missing_td_dirs": [],
    "missing_summary_files": [],
    "missing_accuracy_data": [],
    "partial_completion_dirs": [
      {
        "subdir": "mbpp_sanitized_qwen25coder14b",
        "base_gen_errors": false,
        "td_gen_errors": true,
        "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder14b",
        "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder14b_td"
      }
    ],
    "successful_comparisons": [
      "human_eval_chatgpt4o",
      "human_eval_chatgpt4omini",
      "human_eval_claude35haiku",
      "human_eval_claude35sonnet",
      "human_eval_qwen25coder14b",
      "human_eval_qwen25coder32b",
      "human_eval_qwen25coder3b",
      "human_eval_qwen25coder7b",
      "mbpp_sanitized_chatgpt4o",
      "mbpp_sanitized_chatgpt4omini",
      "mbpp_sanitized_claude35haiku",
      "mbpp_sanitized_claude35sonnet",
      "mbpp_sanitized_qwen25coder32b",
      "mbpp_sanitized_qwen25coder3b",
      "mbpp_sanitized_qwen25coder7b"
    ],
    "config_mismatch_dirs": [],
    "total_directories": 16
  },
  "accuracy_statistics": {
    "increases": [
      2.440000000000012,
      2.4399999999999977,
      4.88000000000001,
      2.440000000000012,
      10.969999999999999,
      4.88000000000001,
      3.6599999999999966,
      7.320000000000007,
      3.289999999999992,
      1.8699999999999903,
      0.9399999999999977,
      1.8799999999999955,
      4.689999999999998,
      4.219999999999999,
      8.450000000000003
    ],
    "total_increase": 64.37000000000002,
    "avg_increase": 4.291333333333335,
    "median_increase": 3.6599999999999966,
    "std_dev": 2.7583816856645367,
    "min_increase": 0.9399999999999977,
    "max_increase": 10.969999999999999,
    "percentile_25": 2.440000000000005,
    "percentile_75": 4.88000000000001,
    "interquartile_range": 2.440000000000005,
    "improved_count": 15,
    "worsened_count": 0,
    "same_count": 0,
    "avg_improvement_pct": 5.304357396147358,
    "avg_regression_pct": 0,
    "confidence_interval": [
      2.763792471222353,
      5.818874195444317
    ],
    "sorted_increases_desc": [
      {
        "benchmark": "human_eval_qwen25coder14b",
        "base_accuracy": 79.27,
        "td_accuracy": 90.24,
        "increase": 10.969999999999999,
        "pct_change": 13.83877885707077
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b",
        "base_accuracy": 72.77,
        "td_accuracy": 81.22,
        "increase": 8.450000000000003,
        "pct_change": 11.611927992304526
      },
      {
        "benchmark": "human_eval_qwen25coder7b",
        "base_accuracy": 76.83,
        "td_accuracy": 84.15,
        "increase": 7.320000000000007,
        "pct_change": 9.527528309254208
      },
      {
        "benchmark": "human_eval_claude35haiku",
        "base_accuracy": 90.24,
        "td_accuracy": 95.12,
        "increase": 4.88000000000001,
        "pct_change": 5.407801418439727
      },
      {
        "benchmark": "human_eval_qwen25coder32b",
        "base_accuracy": 89.02,
        "td_accuracy": 93.9,
        "increase": 4.88000000000001,
        "pct_change": 5.481914176589542
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b",
        "base_accuracy": 84.98,
        "td_accuracy": 89.67,
        "increase": 4.689999999999998,
        "pct_change": 5.518945634266884
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder3b",
        "base_accuracy": 67.14,
        "td_accuracy": 71.36,
        "increase": 4.219999999999999,
        "pct_change": 6.285373845695561
      },
      {
        "benchmark": "human_eval_qwen25coder3b",
        "base_accuracy": 75.61,
        "td_accuracy": 79.27,
        "increase": 3.6599999999999966,
        "pct_change": 4.840629546356298
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4o",
        "base_accuracy": 89.67,
        "td_accuracy": 92.96,
        "increase": 3.289999999999992,
        "pct_change": 3.6690085870413647
      },
      {
        "benchmark": "human_eval_chatgpt4o",
        "base_accuracy": 90.24,
        "td_accuracy": 92.68,
        "increase": 2.440000000000012,
        "pct_change": 2.7039007092198712
      },
      {
        "benchmark": "human_eval_claude35sonnet",
        "base_accuracy": 91.46,
        "td_accuracy": 93.9,
        "increase": 2.440000000000012,
        "pct_change": 2.6678329324294907
      },
      {
        "benchmark": "human_eval_chatgpt4omini",
        "base_accuracy": 87.8,
        "td_accuracy": 90.24,
        "increase": 2.4399999999999977,
        "pct_change": 2.77904328018223
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet",
        "base_accuracy": 93.43,
        "td_accuracy": 95.31,
        "increase": 1.8799999999999955,
        "pct_change": 2.0122016482928347
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini",
        "base_accuracy": 85.45,
        "td_accuracy": 87.32,
        "increase": 1.8699999999999903,
        "pct_change": 2.188414277355167
      },
      {
        "benchmark": "mbpp_sanitized_claude35haiku",
        "base_accuracy": 91.08,
        "td_accuracy": 92.02,
        "increase": 0.9399999999999977,
        "pct_change": 1.0320597277118992
      }
    ],
    "sorted_regressions_asc": [
      {
        "benchmark": "mbpp_sanitized_claude35haiku",
        "base_accuracy": 91.08,
        "td_accuracy": 92.02,
        "increase": 0.9399999999999977,
        "pct_change": 1.0320597277118992
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini",
        "base_accuracy": 85.45,
        "td_accuracy": 87.32,
        "increase": 1.8699999999999903,
        "pct_change": 2.188414277355167
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet",
        "base_accuracy": 93.43,
        "td_accuracy": 95.31,
        "increase": 1.8799999999999955,
        "pct_change": 2.0122016482928347
      },
      {
        "benchmark": "human_eval_chatgpt4omini",
        "base_accuracy": 87.8,
        "td_accuracy": 90.24,
        "increase": 2.4399999999999977,
        "pct_change": 2.77904328018223
      },
      {
        "benchmark": "human_eval_chatgpt4o",
        "base_accuracy": 90.24,
        "td_accuracy": 92.68,
        "increase": 2.440000000000012,
        "pct_change": 2.7039007092198712
      },
      {
        "benchmark": "human_eval_claude35sonnet",
        "base_accuracy": 91.46,
        "td_accuracy": 93.9,
        "increase": 2.440000000000012,
        "pct_change": 2.6678329324294907
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4o",
        "base_accuracy": 89.67,
        "td_accuracy": 92.96,
        "increase": 3.289999999999992,
        "pct_change": 3.6690085870413647
      },
      {
        "benchmark": "human_eval_qwen25coder3b",
        "base_accuracy": 75.61,
        "td_accuracy": 79.27,
        "increase": 3.6599999999999966,
        "pct_change": 4.840629546356298
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder3b",
        "base_accuracy": 67.14,
        "td_accuracy": 71.36,
        "increase": 4.219999999999999,
        "pct_change": 6.285373845695561
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b",
        "base_accuracy": 84.98,
        "td_accuracy": 89.67,
        "increase": 4.689999999999998,
        "pct_change": 5.518945634266884
      },
      {
        "benchmark": "human_eval_claude35haiku",
        "base_accuracy": 90.24,
        "td_accuracy": 95.12,
        "increase": 4.88000000000001,
        "pct_change": 5.407801418439727
      },
      {
        "benchmark": "human_eval_qwen25coder32b",
        "base_accuracy": 89.02,
        "td_accuracy": 93.9,
        "increase": 4.88000000000001,
        "pct_change": 5.481914176589542
      },
      {
        "benchmark": "human_eval_qwen25coder7b",
        "base_accuracy": 76.83,
        "td_accuracy": 84.15,
        "increase": 7.320000000000007,
        "pct_change": 9.527528309254208
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b",
        "base_accuracy": 72.77,
        "td_accuracy": 81.22,
        "increase": 8.450000000000003,
        "pct_change": 11.611927992304526
      },
      {
        "benchmark": "human_eval_qwen25coder14b",
        "base_accuracy": 79.27,
        "td_accuracy": 90.24,
        "increase": 10.969999999999999,
        "pct_change": 13.83877885707077
      }
    ],
    "normality_test_stat": 0.8878082341249389,
    "normality_p_value": 0.06213720886414552,
    "is_normal": true,
    "significance_test_type": "paired_t_test",
    "significance_test_stat": 6.025367199688571,
    "significance_p_value": 3.116011569348066e-05,
    "cohens_d": 0.5752778651317054,
    "effect_size_interpretation": "medium"
  }
}