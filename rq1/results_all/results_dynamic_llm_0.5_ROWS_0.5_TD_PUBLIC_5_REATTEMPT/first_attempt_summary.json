{
  "total_comparisons": 15,
  "td_better": 15,
  "td_same": 0,
  "td_worse": 0,
  "using_remediation": false,
  "details": {
    "human_eval_chatgpt4o": {
      "status": "better",
      "base_accuracy": 78.05,
      "td_accuracy": 90.24,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o_td/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4o_td"
    },
    "human_eval_chatgpt4omini": {
      "status": "better",
      "base_accuracy": 80.49,
      "td_accuracy": 89.02,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_chatgpt4omini_td"
    },
    "human_eval_claude35haiku": {
      "status": "better",
      "base_accuracy": 79.27,
      "td_accuracy": 89.02,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku/results_CLAUDE_35_HAIKU_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku_td/results_CLAUDE_35_HAIKU_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35haiku_td"
    },
    "human_eval_claude35sonnet": {
      "status": "better",
      "base_accuracy": 84.15,
      "td_accuracy": 91.46,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet_td/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_claude35sonnet_td"
    },
    "human_eval_qwen25coder14b": {
      "status": "better",
      "base_accuracy": 79.27,
      "td_accuracy": 90.24,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b/results_QWEN_14B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b_td/results_QWEN_14B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder14b_td"
    },
    "human_eval_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 81.71,
      "td_accuracy": 90.24,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder32b_td"
    },
    "human_eval_qwen25coder3b": {
      "status": "better",
      "base_accuracy": 75.61,
      "td_accuracy": 79.27,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b/results_QWEN_3B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b_td/results_QWEN_3B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder3b_td"
    },
    "human_eval_qwen25coder7b": {
      "status": "better",
      "base_accuracy": 76.83,
      "td_accuracy": 84.15,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b/results_QWEN_7B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b_td/results_QWEN_7B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/human_eval_qwen25coder7b_td"
    },
    "mbpp_sanitized_chatgpt4o": {
      "status": "better",
      "base_accuracy": 74.65,
      "td_accuracy": 89.2,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o_td/results_CHATGPT_4O_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4o_td"
    },
    "mbpp_sanitized_chatgpt4omini": {
      "status": "better",
      "base_accuracy": 75.12,
      "td_accuracy": 83.1,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini_td/results_CHATGPT_4O_MINI_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_chatgpt4omini_td"
    },
    "mbpp_sanitized_claude35haiku": {
      "status": "better",
      "base_accuracy": 73.24,
      "td_accuracy": 84.51,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku/results_CLAUDE_35_HAIKU_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku_td/results_CLAUDE_35_HAIKU_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35haiku_td"
    },
    "mbpp_sanitized_claude35sonnet": {
      "status": "better",
      "base_accuracy": 75.59,
      "td_accuracy": 87.32,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet_td/results_CLAUDE_35_SONNET_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_claude35sonnet_td"
    },
    "mbpp_sanitized_qwen25coder32b": {
      "status": "better",
      "base_accuracy": 73.71,
      "td_accuracy": 84.51,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b_td/results_QWEN_2_5_CODER_32B_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder32b_td"
    },
    "mbpp_sanitized_qwen25coder3b": {
      "status": "better",
      "base_accuracy": 67.14,
      "td_accuracy": 71.36,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b/results_QWEN_3B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b_td/results_QWEN_3B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder3b_td"
    },
    "mbpp_sanitized_qwen25coder7b": {
      "status": "better",
      "base_accuracy": 72.77,
      "td_accuracy": 80.75,
      "using_remediation": false,
      "base_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b/results_QWEN_7B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "td_summary_path": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b_td/results_QWEN_7B_CODER_0.5_ROWS_0.5_TD_PUBLIC_5_REATTEMPT/summary.json",
      "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b",
      "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder7b_td"
    }
  },
  "rq_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1",
  "results_folder": "dynamic",
  "timestamp": "2025-10-16 21:16:11",
  "incomplete_directories": {
    "missing_td_dirs": [],
    "missing_summary_files": [],
    "missing_accuracy_data": [],
    "partial_completion_dirs": [
      {
        "subdir": "mbpp_sanitized_qwen25coder14b",
        "base_gen_errors": false,
        "td_gen_errors": true,
        "base_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder14b",
        "td_dir": "/Users/madnanrizqu/Code/Research/learn/thesis/experiment_runner/../rq1/mbpp_sanitized_qwen25coder14b_td"
      }
    ],
    "successful_comparisons": [
      "human_eval_chatgpt4o",
      "human_eval_chatgpt4omini",
      "human_eval_claude35haiku",
      "human_eval_claude35sonnet",
      "human_eval_qwen25coder14b",
      "human_eval_qwen25coder32b",
      "human_eval_qwen25coder3b",
      "human_eval_qwen25coder7b",
      "mbpp_sanitized_chatgpt4o",
      "mbpp_sanitized_chatgpt4omini",
      "mbpp_sanitized_claude35haiku",
      "mbpp_sanitized_claude35sonnet",
      "mbpp_sanitized_qwen25coder32b",
      "mbpp_sanitized_qwen25coder3b",
      "mbpp_sanitized_qwen25coder7b"
    ],
    "config_mismatch_dirs": [],
    "total_directories": 16
  },
  "accuracy_statistics": {
    "increases": [
      12.189999999999998,
      8.530000000000001,
      9.75,
      7.309999999999988,
      10.969999999999999,
      8.530000000000001,
      3.6599999999999966,
      7.320000000000007,
      14.549999999999997,
      7.97999999999999,
      11.27000000000001,
      11.72999999999999,
      10.800000000000011,
      4.219999999999999,
      7.980000000000004
    ],
    "total_increase": 136.79000000000002,
    "avg_increase": 9.119333333333334,
    "median_increase": 8.530000000000001,
    "std_dev": 2.9352451021207435,
    "min_increase": 3.6599999999999966,
    "max_increase": 14.549999999999997,
    "percentile_25": 7.649999999999999,
    "percentile_75": 11.120000000000005,
    "interquartile_range": 3.470000000000006,
    "improved_count": 15,
    "worsened_count": 0,
    "same_count": 0,
    "avg_improvement_pct": 11.918118750310658,
    "avg_regression_pct": 0,
    "confidence_interval": [
      7.493848775810845,
      10.744817890855822
    ],
    "sorted_increases_desc": [
      {
        "benchmark": "mbpp_sanitized_chatgpt4o",
        "base_accuracy": 74.65,
        "td_accuracy": 89.2,
        "increase": 14.549999999999997,
        "pct_change": 19.490957803081038
      },
      {
        "benchmark": "human_eval_chatgpt4o",
        "base_accuracy": 78.05,
        "td_accuracy": 90.24,
        "increase": 12.189999999999998,
        "pct_change": 15.618193465727096
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet",
        "base_accuracy": 75.59,
        "td_accuracy": 87.32,
        "increase": 11.72999999999999,
        "pct_change": 15.517925651541194
      },
      {
        "benchmark": "mbpp_sanitized_claude35haiku",
        "base_accuracy": 73.24,
        "td_accuracy": 84.51,
        "increase": 11.27000000000001,
        "pct_change": 15.387766247951953
      },
      {
        "benchmark": "human_eval_qwen25coder14b",
        "base_accuracy": 79.27,
        "td_accuracy": 90.24,
        "increase": 10.969999999999999,
        "pct_change": 13.83877885707077
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b",
        "base_accuracy": 73.71,
        "td_accuracy": 84.51,
        "increase": 10.800000000000011,
        "pct_change": 14.65201465201467
      },
      {
        "benchmark": "human_eval_claude35haiku",
        "base_accuracy": 79.27,
        "td_accuracy": 89.02,
        "increase": 9.75,
        "pct_change": 12.29973508262899
      },
      {
        "benchmark": "human_eval_chatgpt4omini",
        "base_accuracy": 80.49,
        "td_accuracy": 89.02,
        "increase": 8.530000000000001,
        "pct_change": 10.597589762703445
      },
      {
        "benchmark": "human_eval_qwen25coder32b",
        "base_accuracy": 81.71,
        "td_accuracy": 90.24,
        "increase": 8.530000000000001,
        "pct_change": 10.439358707624528
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b",
        "base_accuracy": 72.77,
        "td_accuracy": 80.75,
        "increase": 7.980000000000004,
        "pct_change": 10.96605744125327
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini",
        "base_accuracy": 75.12,
        "td_accuracy": 83.1,
        "increase": 7.97999999999999,
        "pct_change": 10.623003194888165
      },
      {
        "benchmark": "human_eval_qwen25coder7b",
        "base_accuracy": 76.83,
        "td_accuracy": 84.15,
        "increase": 7.320000000000007,
        "pct_change": 9.527528309254208
      },
      {
        "benchmark": "human_eval_claude35sonnet",
        "base_accuracy": 84.15,
        "td_accuracy": 91.46,
        "increase": 7.309999999999988,
        "pct_change": 8.686868686868673
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder3b",
        "base_accuracy": 67.14,
        "td_accuracy": 71.36,
        "increase": 4.219999999999999,
        "pct_change": 6.285373845695561
      },
      {
        "benchmark": "human_eval_qwen25coder3b",
        "base_accuracy": 75.61,
        "td_accuracy": 79.27,
        "increase": 3.6599999999999966,
        "pct_change": 4.840629546356298
      }
    ],
    "sorted_regressions_asc": [
      {
        "benchmark": "human_eval_qwen25coder3b",
        "base_accuracy": 75.61,
        "td_accuracy": 79.27,
        "increase": 3.6599999999999966,
        "pct_change": 4.840629546356298
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder3b",
        "base_accuracy": 67.14,
        "td_accuracy": 71.36,
        "increase": 4.219999999999999,
        "pct_change": 6.285373845695561
      },
      {
        "benchmark": "human_eval_claude35sonnet",
        "base_accuracy": 84.15,
        "td_accuracy": 91.46,
        "increase": 7.309999999999988,
        "pct_change": 8.686868686868673
      },
      {
        "benchmark": "human_eval_qwen25coder7b",
        "base_accuracy": 76.83,
        "td_accuracy": 84.15,
        "increase": 7.320000000000007,
        "pct_change": 9.527528309254208
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4omini",
        "base_accuracy": 75.12,
        "td_accuracy": 83.1,
        "increase": 7.97999999999999,
        "pct_change": 10.623003194888165
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder7b",
        "base_accuracy": 72.77,
        "td_accuracy": 80.75,
        "increase": 7.980000000000004,
        "pct_change": 10.96605744125327
      },
      {
        "benchmark": "human_eval_chatgpt4omini",
        "base_accuracy": 80.49,
        "td_accuracy": 89.02,
        "increase": 8.530000000000001,
        "pct_change": 10.597589762703445
      },
      {
        "benchmark": "human_eval_qwen25coder32b",
        "base_accuracy": 81.71,
        "td_accuracy": 90.24,
        "increase": 8.530000000000001,
        "pct_change": 10.439358707624528
      },
      {
        "benchmark": "human_eval_claude35haiku",
        "base_accuracy": 79.27,
        "td_accuracy": 89.02,
        "increase": 9.75,
        "pct_change": 12.29973508262899
      },
      {
        "benchmark": "mbpp_sanitized_qwen25coder32b",
        "base_accuracy": 73.71,
        "td_accuracy": 84.51,
        "increase": 10.800000000000011,
        "pct_change": 14.65201465201467
      },
      {
        "benchmark": "human_eval_qwen25coder14b",
        "base_accuracy": 79.27,
        "td_accuracy": 90.24,
        "increase": 10.969999999999999,
        "pct_change": 13.83877885707077
      },
      {
        "benchmark": "mbpp_sanitized_claude35haiku",
        "base_accuracy": 73.24,
        "td_accuracy": 84.51,
        "increase": 11.27000000000001,
        "pct_change": 15.387766247951953
      },
      {
        "benchmark": "mbpp_sanitized_claude35sonnet",
        "base_accuracy": 75.59,
        "td_accuracy": 87.32,
        "increase": 11.72999999999999,
        "pct_change": 15.517925651541194
      },
      {
        "benchmark": "human_eval_chatgpt4o",
        "base_accuracy": 78.05,
        "td_accuracy": 90.24,
        "increase": 12.189999999999998,
        "pct_change": 15.618193465727096
      },
      {
        "benchmark": "mbpp_sanitized_chatgpt4o",
        "base_accuracy": 74.65,
        "td_accuracy": 89.2,
        "increase": 14.549999999999997,
        "pct_change": 19.490957803081038
      }
    ],
    "normality_test_stat": 0.9660688241701777,
    "normality_p_value": 0.7961891797841154,
    "is_normal": true,
    "significance_test_type": "paired_t_test",
    "significance_test_stat": 12.03273488234282,
    "significance_p_value": 9.031840813122684e-09,
    "cohens_d": 1.875976492489565,
    "effect_size_interpretation": "large"
  }
}